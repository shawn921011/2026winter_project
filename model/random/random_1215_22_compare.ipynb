{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== nonrepeat_cnt_per_user ====================\n",
      "[2025-12-15] train_rows=1,536 test_rows=192  RMSE=0.049356  MAE=0.034668\n",
      "[2025-12-22] train_rows=1,728 test_rows=192  RMSE=0.071611  MAE=0.050776\n",
      "[Overall 2 weeks] test_rows=384  RMSE=0.061499  MAE=0.042722\n",
      "\n",
      "==================== trip_cnt_per_user ====================\n",
      "[2025-12-15] train_rows=1,536 test_rows=192  RMSE=0.040214  MAE=0.026897\n",
      "[2025-12-22] train_rows=1,728 test_rows=192  RMSE=0.053683  MAE=0.035547\n",
      "[Overall 2 weeks] test_rows=384  RMSE=0.047429  MAE=0.031222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "DATA_PATH = \"../../final_data/data_260125_random.csv\"\n",
    "DATE_COL = \"experiment_date\"\n",
    "\n",
    "TARGET_WEEKS = [pd.Timestamp(\"2025-12-15\"), pd.Timestamp(\"2025-12-22\")]\n",
    "\n",
    "Y_COLS = [\"nonrepeat_cnt_per_user\", \"trip_cnt_per_user\"]\n",
    "\n",
    "CAT_COLS = [\"treatment\", \"source\", \"ops_type_merged\", \"city_group\"]\n",
    "\n",
    "NUM_FEATURES = [\n",
    "    \"avg_rainy_day\",\n",
    "    \"avg_rainy_weekday\",\n",
    "    \"avg_rainy_weekend\",\n",
    "    \"mgm_day\",\n",
    "    \"nonrepeat_cnt_per_user_lag2\",\n",
    "    \"nonrepeat_cnt_per_user_roll4\",\n",
    "    \"trip_cnt_per_user_lag2\",\n",
    "    \"trip_cnt_per_user_roll4\",\n",
    "    \"weekday_nonrepeat_cnt_per_user_lag2\",\n",
    "    \"weekday_nonrepeat_cnt_per_user_roll4\",\n",
    "    \"weekday_trip_cnt_per_user_lag2\",\n",
    "    \"weekday_trip_cnt_per_user_roll4\",\n",
    "    \"weekday_match_rate_lag2\",\n",
    "    \"weekday_match_rate_roll4\",\n",
    "    \"weekend_nonrepeat_cnt_per_user_lag2\",\n",
    "    \"weekend_nonrepeat_cnt_per_user_roll4\",\n",
    "    \"weekend_trip_cnt_per_user_lag2\",\n",
    "    \"weekend_trip_cnt_per_user_roll4\",\n",
    "    \"weekend_match_rate_lag2\",\n",
    "    \"weekend_match_rate_roll4\",\n",
    "    \"has_national_holiday\",\n",
    "    \"coupon_BD_per_user_log1p_lag2\",\n",
    "    \"coupon_BD_per_user_log1p_roll4\",\n",
    "    \"coupon_CDP_per_user_log1p_lag2\",\n",
    "    \"coupon_CDP_per_user_log1p_roll4\",\n",
    "    \"coupon_folk_per_user_log1p_lag2\",\n",
    "    \"coupon_folk_per_user_log1p_roll4\",\n",
    "    \"coupon_growth_other_per_user_log1p_lag2\",\n",
    "    \"coupon_growth_other_per_user_log1p_roll4\",\n",
    "    \"coupon_MGM_per_user_log1p_lag2\",\n",
    "    \"coupon_MGM_per_user_log1p_roll4\",\n",
    "    \"coupon_MKT_per_user_log1p_lag2\",\n",
    "    \"coupon_MKT_per_user_log1p_roll4\",\n",
    "    \"coupon_register_per_user_log1p_lag2\",\n",
    "    \"coupon_register_per_user_log1p_roll4\",\n",
    "    \"coupon_daily_per_user_log1p_lag2\",\n",
    "    \"coupon_daily_per_user_log1p_roll4\",\n",
    "]\n",
    "\n",
    "# --------------------------\n",
    "# Load\n",
    "# --------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "df = df[df[DATE_COL].notna()].copy()\n",
    "\n",
    "# 只保留到最大 target week 為止（後面不會用到）\n",
    "df = df[df[DATE_COL] <= max(TARGET_WEEKS)].copy()\n",
    "\n",
    "# categorical cast\n",
    "for c in CAT_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# feature availability check\n",
    "missing_num = [c for c in NUM_FEATURES if c not in df.columns]\n",
    "missing_cat = [c for c in CAT_COLS if c not in df.columns]\n",
    "if missing_cat:\n",
    "    print(\"[WARN] Missing categorical cols (will be dropped):\", missing_cat)\n",
    "if missing_num:\n",
    "    print(\"[WARN] Missing numeric features (will be dropped):\", missing_num)\n",
    "\n",
    "X_COLS = [c for c in CAT_COLS if c in df.columns] + [c for c in NUM_FEATURES if c in df.columns]\n",
    "CAT_IN_X = [c for c in CAT_COLS if c in df.columns]\n",
    "\n",
    "# --------------------------\n",
    "# Helpers\n",
    "# --------------------------\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mae(y_true, y_pred) -> float:\n",
    "    return float(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "def fit_predict_one_week(df_all: pd.DataFrame, target_week: pd.Timestamp, y_col: str):\n",
    "    # 嚴格遵守：只能拿 target_week 之前的資料訓練\n",
    "    train_df = df_all[df_all[DATE_COL] < target_week].copy()\n",
    "    test_df  = df_all[df_all[DATE_COL] == target_week].copy()\n",
    "\n",
    "    # drop rows with missing target\n",
    "    train_df = train_df[train_df[y_col].notna()].copy()\n",
    "    test_df  = test_df[test_df[y_col].notna()].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        return None, None, len(train_df), len(test_df)\n",
    "\n",
    "    X_train = train_df[X_COLS]\n",
    "    y_train = train_df[y_col].astype(float)\n",
    "\n",
    "    X_test = test_df[X_COLS]\n",
    "    y_test = test_df[y_col].astype(float)\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=63,\n",
    "        min_child_samples=300,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=5.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    # categorical_feature: 用欄名即可\n",
    "    model.fit(X_train, y_train, categorical_feature=[c for c in CAT_IN_X if c in X_train.columns])\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test.values, y_pred, len(train_df), len(test_df)\n",
    "\n",
    "# --------------------------\n",
    "# Run + Print metrics\n",
    "# --------------------------\n",
    "for y_col in Y_COLS:\n",
    "    print(f\"\\n==================== {y_col} ====================\")\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    for tw in TARGET_WEEKS:\n",
    "        y_true, y_pred, n_tr, n_te = fit_predict_one_week(df, tw, y_col)\n",
    "        if y_true is None:\n",
    "            print(f\"[{tw.date()}] SKIP (train_rows={n_tr:,}, test_rows={n_te:,})\")\n",
    "            continue\n",
    "\n",
    "        r = rmse(y_true, y_pred)\n",
    "        m = mae(y_true, y_pred)\n",
    "        print(f\"[{tw.date()}] train_rows={n_tr:,} test_rows={n_te:,}  RMSE={r:.6f}  MAE={m:.6f}\")\n",
    "\n",
    "        all_y_true.append(y_true)\n",
    "        all_y_pred.append(y_pred)\n",
    "\n",
    "    if all_y_true:\n",
    "        all_y_true = np.concatenate(all_y_true)\n",
    "        all_y_pred = np.concatenate(all_y_pred)\n",
    "        print(f\"[Overall 2 weeks] test_rows={len(all_y_true):,}  RMSE={rmse(all_y_true, all_y_pred):.6f}  MAE={mae(all_y_true, all_y_pred):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c087473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== trip_cnt_per_user (ONLY specified groups) ====================\n",
      "[2025-12-15] train_rows=1,536 test_rows=48 RMSE=0.029264 MAE=0.022822\n",
      "[2025-12-22] train_rows=1,728 test_rows=48 RMSE=0.068643 MAE=0.041979\n",
      "[Overall 2 weeks] test_rows=96 RMSE=0.052765 MAE=0.032401\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "DATA_PATH = \"../../final_data/data_260125_random.csv\"\n",
    "DATE_COL = \"experiment_date\"\n",
    "TARGET_WEEKS = [pd.Timestamp(\"2025-12-15\"), pd.Timestamp(\"2025-12-22\")]\n",
    "Y_COL = \"trip_cnt_per_user\"\n",
    "\n",
    "CAT_COLS = [\"ops_type_merged\", \"city_group\"]\n",
    "NUM_FEATURES = [\n",
    "    \"avg_rainy_day\",\n",
    "    \"avg_rainy_weekday\",\n",
    "    \"avg_rainy_weekend\",\n",
    "    \"mgm_day\",\n",
    "    \"nonrepeat_cnt_per_user_lag2\",\n",
    "    \"nonrepeat_cnt_per_user_roll4\",\n",
    "    \"trip_cnt_per_user_lag2\",\n",
    "    \"trip_cnt_per_user_roll4\",\n",
    "    \"weekday_nonrepeat_cnt_per_user_lag2\",\n",
    "    \"weekday_nonrepeat_cnt_per_user_roll4\",\n",
    "    \"weekday_trip_cnt_per_user_lag2\",\n",
    "    \"weekday_trip_cnt_per_user_roll4\",\n",
    "    \"weekday_match_rate_lag2\",\n",
    "    \"weekday_match_rate_roll4\",\n",
    "    \"weekend_nonrepeat_cnt_per_user_lag2\",\n",
    "    \"weekend_nonrepeat_cnt_per_user_roll4\",\n",
    "    \"weekend_trip_cnt_per_user_lag2\",\n",
    "    \"weekend_trip_cnt_per_user_roll4\",\n",
    "    \"weekend_match_rate_lag2\",\n",
    "    \"weekend_match_rate_roll4\",\n",
    "    \"has_national_holiday\",\n",
    "    \"coupon_BD_per_user_log1p_lag2\",\n",
    "    \"coupon_BD_per_user_log1p_roll4\",\n",
    "    \"coupon_CDP_per_user_log1p_lag2\",\n",
    "    \"coupon_CDP_per_user_log1p_roll4\",\n",
    "    \"coupon_folk_per_user_log1p_lag2\",\n",
    "    \"coupon_folk_per_user_log1p_roll4\",\n",
    "    \"coupon_growth_other_per_user_log1p_lag2\",\n",
    "    \"coupon_growth_other_per_user_log1p_roll4\",\n",
    "    \"coupon_MGM_per_user_log1p_lag2\",\n",
    "    \"coupon_MGM_per_user_log1p_roll4\",\n",
    "    \"coupon_MKT_per_user_log1p_lag2\",\n",
    "    \"coupon_MKT_per_user_log1p_roll4\",\n",
    "    \"coupon_register_per_user_log1p_lag2\",\n",
    "    \"coupon_register_per_user_log1p_roll4\",\n",
    "    \"coupon_daily_per_user_log1p_lag2\",\n",
    "    \"coupon_daily_per_user_log1p_roll4\",\n",
    "    \"face_value\",\n",
    "    \"face_value_num\"\n",
    "]\n",
    "\n",
    "# --------------------------\n",
    "# 指定要評估的組別清單（兩週；只考慮 1 張；排除 25）\n",
    "# key: (experiment_date, city_group, ops_type_merged, treatment)\n",
    "# --------------------------\n",
    "GROUP_ROWS = []\n",
    "\n",
    "def add_rows(week_str, city, sub_group, face_values):\n",
    "    for fv in face_values:\n",
    "        if fv == 25:\n",
    "            continue  # 排除 25\n",
    "        GROUP_ROWS.append({\n",
    "            \"experiment_date\": pd.Timestamp(week_str),\n",
    "            \"city_group\": city,\n",
    "            \"ops_type_merged\": sub_group,\n",
    "            \"treatment\": f\"{int(fv)}元1張\",\n",
    "        })\n",
    "\n",
    "for w in [\"2025-12-15\", \"2025-12-22\"]:\n",
    "    for city in [\"中區\", \"北區\", \"南區\"]:\n",
    "        add_rows(w, city, \"14天在其他尖峰預估車資\", [15, 20])\n",
    "        add_rows(w, city, \"14天在晚尖峰預估車資\", [15, 20])\n",
    "        add_rows(w, city, \"90天在尖峰預估車資\", [20, 30])\n",
    "        add_rows(w, city, \"喚回-其他\", [20, 30])\n",
    "        add_rows(w, city, \"喚回-高優惠敏感\", [20, 30])\n",
    "        add_rows(w, city, \"既有regular鞏固\", [15, 20, 25])  # 25 自動排除\n",
    "        add_rows(w, city, \"養成Regular-其他\", [20, 30])\n",
    "        add_rows(w, city, \"養成Regular-高優惠敏感\", [20, 30])\n",
    "\n",
    "groups_df = pd.DataFrame(GROUP_ROWS).drop_duplicates()\n",
    "\n",
    "# --------------------------\n",
    "# Load\n",
    "# --------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "df = df[df[DATE_COL].notna()].copy()\n",
    "\n",
    "# 只保留到最大 target week（後面不會用到）\n",
    "df = df[df[DATE_COL] <= max(TARGET_WEEKS)].copy()\n",
    "\n",
    "# categorical cast（只在這裡做一次）\n",
    "for c in CAT_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# feature availability check\n",
    "missing_num = [c for c in NUM_FEATURES if c not in df.columns]\n",
    "missing_cat = [c for c in CAT_COLS if c not in df.columns]\n",
    "if missing_cat:\n",
    "    print(\"[WARN] Missing categorical cols (will be dropped):\", missing_cat)\n",
    "if missing_num:\n",
    "    print(\"[WARN] Missing numeric features (will be dropped):\", missing_num)\n",
    "\n",
    "X_COLS = [c for c in CAT_COLS if c in df.columns] + [c for c in NUM_FEATURES if c in df.columns]\n",
    "CAT_IN_X = [c for c in CAT_COLS if c in df.columns]\n",
    "\n",
    "# --------------------------\n",
    "# Helpers\n",
    "# --------------------------\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mae(y_true, y_pred) -> float:\n",
    "    return float(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "def align_categories(train_df: pd.DataFrame, test_df: pd.DataFrame, cat_cols):\n",
    "    \"\"\"\n",
    "    保證 train/test 的 categorical dtype & categories 完全一致：\n",
    "    test categories 強制沿用 train 的 categories（同集合、同順序）。\n",
    "    \"\"\"\n",
    "    for c in cat_cols:\n",
    "        if c in train_df.columns and c in test_df.columns:\n",
    "            train_df[c] = train_df[c].astype(\"category\")\n",
    "            test_df[c] = test_df[c].astype(\"category\")\n",
    "            test_df[c] = test_df[c].cat.set_categories(train_df[c].cat.categories)\n",
    "    return train_df, test_df\n",
    "\n",
    "def filter_to_groups(test_df: pd.DataFrame, target_week: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    只保留你表格中有出現的組別 (week+city+ops_type+treatment)。\n",
    "    重要：不轉 dtype、不 merge，避免 categorical mismatch。\n",
    "    \"\"\"\n",
    "    key_cols = [\"experiment_date\", \"city_group\", \"ops_type_merged\", \"treatment\"]\n",
    "    g = groups_df[groups_df[\"experiment_date\"] == target_week][key_cols].drop_duplicates()\n",
    "\n",
    "    g_keys = set(map(tuple, g.itertuples(index=False, name=None)))\n",
    "    test_keys = list(map(tuple, test_df[key_cols].itertuples(index=False, name=None)))\n",
    "    mask = [k in g_keys for k in test_keys]\n",
    "    return test_df.loc[mask].copy()\n",
    "\n",
    "def fit_predict_one_week_on_groups(df_all: pd.DataFrame, target_week: pd.Timestamp):\n",
    "    # 只能拿 target_week 之前的資料訓練\n",
    "    train_df = df_all[df_all[DATE_COL] < target_week].copy()\n",
    "    test_df  = df_all[df_all[DATE_COL] == target_week].copy()\n",
    "\n",
    "    # test 只挑指定組別（不改 dtype）\n",
    "    test_df = filter_to_groups(test_df, target_week)\n",
    "\n",
    "    # drop rows with missing target\n",
    "    train_df = train_df[train_df[Y_COL].notna()].copy()\n",
    "    test_df  = test_df[test_df[Y_COL].notna()].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        return None, None, len(train_df), len(test_df)\n",
    "\n",
    "    # ✅ 對齊 categories，確保 predict 不會 categorical mismatch\n",
    "    train_df, test_df = align_categories(train_df, test_df, CAT_IN_X)\n",
    "\n",
    "    X_train = train_df[X_COLS]\n",
    "    y_train = train_df[Y_COL].astype(float)\n",
    "\n",
    "    X_test = test_df[X_COLS]\n",
    "    y_test = test_df[Y_COL].astype(float)\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        n_estimators=2200,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=63,\n",
    "        min_child_samples=150,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=1.0,\n",
    "        reg_alpha=3.5,\n",
    "        reg_lambda=2.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        categorical_feature=[c for c in CAT_IN_X if c in X_train.columns]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test.values, y_pred, len(train_df), len(test_df)\n",
    "\n",
    "# --------------------------\n",
    "# Run + Print metrics (只對「指定組別」算 trip_cnt_per_user)\n",
    "# --------------------------\n",
    "print(f\"\\n==================== {Y_COL} (ONLY specified groups) ====================\")\n",
    "all_y_true, all_y_pred = [], []\n",
    "\n",
    "for tw in TARGET_WEEKS:\n",
    "    y_true, y_pred, n_tr, n_te = fit_predict_one_week_on_groups(df, tw)\n",
    "    if y_true is None:\n",
    "        print(f\"[{tw.date()}] SKIP (train_rows={n_tr:,}, test_rows={n_te:,})\")\n",
    "        continue\n",
    "    print(f\"[{tw.date()}] train_rows={n_tr:,} test_rows={n_te:,} RMSE={rmse(y_true, y_pred):.6f} MAE={mae(y_true, y_pred):.6f}\")\n",
    "    all_y_true.append(y_true)\n",
    "    all_y_pred.append(y_pred)\n",
    "\n",
    "if all_y_true:\n",
    "    all_y_true = np.concatenate(all_y_true)\n",
    "    all_y_pred = np.concatenate(all_y_pred)\n",
    "    print(f\"[Overall 2 weeks] test_rows={len(all_y_true):,} RMSE={rmse(all_y_true, all_y_pred):.6f} MAE={mae(all_y_true, all_y_pred):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64ee3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bad98bddca43cd89cfc85a9c8d584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Optuna Best Result =====\n",
      "Best RMSE (avg over 2 weeks): 0.04877249529813014\n",
      "Best params: {'learning_rate': 0.014672871245679103, 'n_estimators': 2200, 'num_leaves': 63, 'min_child_samples': 125, 'subsample': 0.65, 'colsample_bytree': 1.0, 'reg_alpha': 3.486636659858854, 'reg_lambda': 2.0235598656898537}\n",
      "\n",
      "==================== trip_cnt_per_user (BEST params, ONLY specified groups) ====================\n",
      "[2025-12-15] train_rows=1,536 test_rows=48 RMSE=0.029175 MAE=0.022394\n",
      "[2025-12-22] train_rows=1,728 test_rows=48 RMSE=0.068370 MAE=0.042161\n",
      "[Overall 2 weeks] test_rows=96 RMSE=0.052562 MAE=0.032278\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Optuna tuning (around your current params)\n",
    "# - Objective: avg RMSE over 2025-12-15 & 2025-12-22\n",
    "# - Evaluation: ONLY specified groups (your groups_df)\n",
    "# - Training constraint: ONLY use data strictly before each target week\n",
    "# ==========================\n",
    "\n",
    "import optuna\n",
    "\n",
    "# ---- (optional) make optuna quieter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "BASE_PARAMS = dict(\n",
    "    objective=\"regression\",\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=300,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=5.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "def fit_predict_one_week_on_groups_with_params(df_all: pd.DataFrame, target_week: pd.Timestamp, model_params: dict):\n",
    "    train_df = df_all[df_all[DATE_COL] < target_week].copy()\n",
    "    test_df  = df_all[df_all[DATE_COL] == target_week].copy()\n",
    "\n",
    "    test_df = filter_to_groups(test_df, target_week)\n",
    "\n",
    "    train_df = train_df[train_df[Y_COL].notna()].copy()\n",
    "    test_df  = test_df[test_df[Y_COL].notna()].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        return None, None, len(train_df), len(test_df)\n",
    "\n",
    "    # align categorical categories\n",
    "    train_df, test_df = align_categories(train_df, test_df, CAT_IN_X)\n",
    "\n",
    "    X_train = train_df[X_COLS]\n",
    "    y_train = train_df[Y_COL].astype(float)\n",
    "\n",
    "    X_test = test_df[X_COLS]\n",
    "    y_test = test_df[Y_COL].astype(float)\n",
    "\n",
    "    model = lgb.LGBMRegressor(**model_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        categorical_feature=[c for c in CAT_IN_X if c in X_train.columns],\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test.values, y_pred, len(train_df), len(test_df)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # --- search space (centered around your current settings)\n",
    "    params = dict(BASE_PARAMS)\n",
    "\n",
    "    # keep learning_rate & n_estimators in a sensible tradeoff range\n",
    "    params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 0.012, 0.035, log=True)\n",
    "    params[\"n_estimators\"]  = trial.suggest_int(\"n_estimators\", 1200, 3200, step=200)\n",
    "\n",
    "    params[\"num_leaves\"] = trial.suggest_int(\"num_leaves\", 31, 255, step=8)\n",
    "\n",
    "    # min_child_samples around 300 but allow +- a lot\n",
    "    params[\"min_child_samples\"] = trial.suggest_int(\"min_child_samples\", 50, 600, step=25)\n",
    "\n",
    "    params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.05)\n",
    "    params[\"colsample_bytree\"] = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0, step=0.05)\n",
    "\n",
    "    # regularization around (1,5)\n",
    "    params[\"reg_alpha\"] = trial.suggest_float(\"reg_alpha\", 0.0, 5.0)\n",
    "    params[\"reg_lambda\"] = trial.suggest_float(\"reg_lambda\", 0.0, 15.0)\n",
    "\n",
    "    # ---- evaluate on your 2 target weeks (ONLY specified groups)\n",
    "    rmses = []\n",
    "    for tw in TARGET_WEEKS:\n",
    "        y_true, y_pred, n_tr, n_te = fit_predict_one_week_on_groups_with_params(df, tw, params)\n",
    "        if y_true is None or len(y_true) == 0:\n",
    "            # no test rows -> heavily penalize (shouldn't happen if groups exist)\n",
    "            return 1e9\n",
    "        rmses.append(rmse(y_true, y_pred))\n",
    "\n",
    "        # report intermediate value for pruning\n",
    "        trial.report(float(np.mean(rmses)), step=len(rmses))\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(rmses))\n",
    "\n",
    "# ---- run study\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=0)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective, n_trials=60, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n===== Optuna Best Result =====\")\n",
    "print(\"Best RMSE (avg over 2 weeks):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# ---- evaluate best params with RMSE + MAE (and print per-week + overall)\n",
    "best_params = dict(BASE_PARAMS)\n",
    "best_params.update(study.best_params)\n",
    "\n",
    "print(f\"\\n==================== {Y_COL} (BEST params, ONLY specified groups) ====================\")\n",
    "all_y_true, all_y_pred = [], []\n",
    "\n",
    "for tw in TARGET_WEEKS:\n",
    "    y_true, y_pred, n_tr, n_te = fit_predict_one_week_on_groups_with_params(df, tw, best_params)\n",
    "    if y_true is None:\n",
    "        print(f\"[{tw.date()}] SKIP (train_rows={n_tr:,}, test_rows={n_te:,})\")\n",
    "        continue\n",
    "    print(f\"[{tw.date()}] train_rows={n_tr:,} test_rows={n_te:,} RMSE={rmse(y_true, y_pred):.6f} MAE={mae(y_true, y_pred):.6f}\")\n",
    "    all_y_true.append(y_true)\n",
    "    all_y_pred.append(y_pred)\n",
    "\n",
    "if all_y_true:\n",
    "    all_y_true = np.concatenate(all_y_true)\n",
    "    all_y_pred = np.concatenate(all_y_pred)\n",
    "    print(f\"[Overall 2 weeks] test_rows={len(all_y_true):,} RMSE={rmse(all_y_true, all_y_pred):.6f} MAE={mae(all_y_true, all_y_pred):.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv) 2026winter_project",
   "language": "python",
   "name": "2026winter_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
