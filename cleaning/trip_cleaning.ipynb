{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf4bec0",
   "metadata": {},
   "source": [
    "# 整理趟次資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd27062",
   "metadata": {},
   "source": [
    "## 合併資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87615b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhsiang.chang\\AppData\\Local\\Temp\\ipykernel_21388\\848396600.py:15: DtypeWarning: Columns (44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "C:\\Users\\minhsiang.chang\\AppData\\Local\\Temp\\ipykernel_21388\\848396600.py:15: DtypeWarning: Columns (44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "C:\\Users\\minhsiang.chang\\AppData\\Local\\Temp\\ipykernel_21388\\848396600.py:15: DtypeWarning: Columns (44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (6333679, 57)\n",
      "Saved to: ../merged_data\\RDS_trip_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "files = [os.path.join(DATA_DIR, f\"RDS_trip_{i}.csv\") for i in range(1, 6)]\n",
    "\n",
    "# 檢查檔案是否存在\n",
    "missing = [f for f in files if not os.path.exists(f)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\"找不到以下檔案：\\n\" + \"\\n\".join(missing))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "# 合併（保留所有欄位；欄位不一致會自動對齊）\n",
    "rds_trip_merged = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "\n",
    "out_path = os.path.join(\"../merged_data\", \"RDS_trip_merged.csv\")\n",
    "rds_trip_merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Merged shape:\", rds_trip_merged.shape)\n",
    "print(\"Saved to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2985f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (6335051, 21)\n",
      "Saved to: ../merged_data\\trip_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "files = [os.path.join(DATA_DIR, f\"trip_{i}.csv\") for i in range(1, 4)]\n",
    "\n",
    "# 檢查檔案是否存在\n",
    "missing = [f for f in files if not os.path.exists(f)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\"找不到以下檔案：\\n\" + \"\\n\".join(missing))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "# 合併（保留所有欄位；欄位不一致會自動對齊）\n",
    "trip_merged = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "\n",
    "out_path = os.path.join(\"../merged_data\", \"trip_merged.csv\")\n",
    "trip_merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Merged shape:\", trip_merged.shape)\n",
    "print(\"Saved to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1962bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhsiang.chang\\AppData\\Local\\Temp\\ipykernel_21388\\3863761015.py:15: DtypeWarning: Columns (55,58,60,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "C:\\Users\\minhsiang.chang\\AppData\\Local\\Temp\\ipykernel_21388\\3863761015.py:15: DtypeWarning: Columns (55,58,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (4061235, 66)\n",
      "Saved to: ../merged_data\\trip_label_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "files = [os.path.join(DATA_DIR, f\"trip_label_{i}.csv\") for i in range(1, 3)]\n",
    "\n",
    "# 檢查檔案是否存在\n",
    "missing = [f for f in files if not os.path.exists(f)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\"找不到以下檔案：\\n\" + \"\\n\".join(missing))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "# 合併（保留所有欄位；欄位不一致會自動對齊）\n",
    "trip_label_merged = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "\n",
    "out_path = os.path.join(\"../merged_data\", \"trip_label_merged.csv\")\n",
    "trip_label_merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Merged shape:\", trip_label_merged.shape)\n",
    "print(\"Saved to:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c48c74",
   "metadata": {},
   "source": [
    "## 處理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ed8d0",
   "metadata": {},
   "source": [
    "## 準備key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea745c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TZ = \"Asia/Taipei\"\n",
    "HOLIDAYS_MD = {(9,29),(10,6),(10,10),(10,24),(12,25),(1,1)}\n",
    "\n",
    "def rds_unixtime_to_local_date(s):\n",
    "    return pd.to_datetime(s, unit=\"s\", utc=True, errors=\"coerce\").dt.tz_convert(TZ).dt.date\n",
    "\n",
    "def week_monday_from_date(d):\n",
    "    dd = pd.to_datetime(d, errors=\"coerce\")\n",
    "    return (dd - pd.to_timedelta(dd.dt.weekday, unit=\"D\")).dt.date\n",
    "\n",
    "def add_weekend_flag_from_weekday_md(df):\n",
    "    is_weekend = df[\"weekday\"].isin([1,7])\n",
    "    md = list(zip(df[\"month\"], df[\"day\"]))\n",
    "    is_holiday = pd.Series([x in HOLIDAYS_MD for x in md], index=df.index)\n",
    "    df[\"is_weekend\"] = is_weekend | is_holiday\n",
    "    df[\"is_weekday\"] = ~df[\"is_weekend\"]\n",
    "    return df\n",
    "\n",
    "# --- 讀小檔 ---\n",
    "user_cleaned = pd.read_csv(\"../cleaned_data/user_cleaned.csv\", dtype={\"user_id\":\"int64\"})\n",
    "target_user_ids = set(user_cleaned[\"user_id\"].unique())\n",
    "\n",
    "test_trip = pd.read_csv(\"../data/test_trip.csv\", usecols=[\"trip_id\"], dtype={\"trip_id\":\"int64\"})\n",
    "test_trip_ids = set(test_trip[\"trip_id\"].unique())\n",
    "\n",
    "target_date_start = pd.to_datetime(\"2025-07-28\").date()\n",
    "target_date_end   = pd.to_datetime(\"2026-01-11\").date()\n",
    "start_minus_60 = (pd.to_datetime(target_date_start) - pd.Timedelta(days=60)).date()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f10a0",
   "metadata": {},
   "source": [
    "## trip_stats_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0629fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "RDS_PATH = \"../merged_data/RDS_trip_merged.csv\"\n",
    "\n",
    "usecols_rds = [\"trip_id\",\"user_id\",\"reserve_time\",\"duplicate_id\",\"month\",\"day\",\"weekday\"]\n",
    "dtype_rds = {\n",
    "    \"trip_id\":\"int64\",\n",
    "    \"user_id\":\"int64\",\n",
    "    \"reserve_time\":\"int64\",\n",
    "    \"duplicate_id\":\"int64\",\n",
    "    \"month\":\"int16\",\n",
    "    \"day\":\"int16\",\n",
    "    \"weekday\":\"int8\",\n",
    "}\n",
    "\n",
    "agg = defaultdict(lambda: [0,0,0])  # [weekday_nonrepeat, weekend_nonrepeat, nonrepeat]\n",
    "ts_trip_ids = set()\n",
    "\n",
    "chunksize = 500_000\n",
    "\n",
    "for chunk in pd.read_csv(RDS_PATH, usecols=usecols_rds, dtype=dtype_rds, chunksize=chunksize):\n",
    "    # filters\n",
    "    chunk = chunk[chunk[\"duplicate_id\"].fillna(0).astype(int) == 0]\n",
    "    chunk = chunk[~chunk[\"trip_id\"].isin(test_trip_ids)]\n",
    "    chunk = chunk[chunk[\"user_id\"].isin(target_user_ids)]\n",
    "\n",
    "    # trip_date & date filter\n",
    "    chunk[\"trip_date\"] = rds_unixtime_to_local_date(chunk[\"reserve_time\"])\n",
    "    chunk = chunk[chunk[\"trip_date\"].between(target_date_start, target_date_end)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # week & weekend flag\n",
    "    chunk[\"week\"] = week_monday_from_date(chunk[\"trip_date\"])\n",
    "    chunk = add_weekend_flag_from_weekday_md(chunk)\n",
    "\n",
    "    # collect trip ids for later join with trip\n",
    "    ts_trip_ids.update(chunk[\"trip_id\"].tolist())\n",
    "\n",
    "    # group and accumulate\n",
    "    g = chunk.groupby([\"user_id\",\"week\"], as_index=False).agg(\n",
    "        weekday_nonrepeat_cnt=(\"is_weekday\",\"sum\"),\n",
    "        weekend_nonrepeat_cnt=(\"is_weekend\",\"sum\"),\n",
    "        nonrepeat_cnt=(\"trip_id\",\"size\"),\n",
    "    )\n",
    "    for row in g.itertuples(index=False):\n",
    "        key = (int(row.user_id), row.week)\n",
    "        agg[key][0] += int(row.weekday_nonrepeat_cnt)\n",
    "        agg[key][1] += int(row.weekend_nonrepeat_cnt)\n",
    "        agg[key][2] += int(row.nonrepeat_cnt)\n",
    "\n",
    "trip_stats_agg = pd.DataFrame(\n",
    "    [(k[0], k[1], v[0], v[1], v[2]) for k, v in agg.items()],\n",
    "    columns=[\"user_id\",\"week\",\"weekday_nonrepeat_cnt\",\"weekend_nonrepeat_cnt\",\"nonrepeat_cnt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc2875",
   "metadata": {},
   "source": [
    "## trip_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIP_PATH = \"../merged_data/trip_merged.csv\"\n",
    "\n",
    "usecols_trip = [\"trip_id\",\"user_id\",\"request_time\",\"reserve_time\",\"driver_id\"]\n",
    "dtype_trip = {\"trip_id\":\"int64\", \"user_id\":\"int64\"}\n",
    "\n",
    "def utc_string_to_local_date(s):\n",
    "    return pd.to_datetime(s, utc=True, errors=\"coerce\").dt.tz_convert(TZ).dt.date\n",
    "\n",
    "def add_weekend_flag_from_date(df, date_col):\n",
    "    d = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    pd_dow = d.dt.dayofweek\n",
    "    bq_dow = ((pd_dow + 1) % 7) + 1\n",
    "    is_weekend = bq_dow.isin([1,7])\n",
    "    md = list(zip(d.dt.month, d.dt.day))\n",
    "    is_holiday = pd.Series([x in HOLIDAYS_MD for x in md], index=df.index)\n",
    "    df[\"is_weekend\"] = is_weekend | is_holiday\n",
    "    df[\"is_weekday\"] = ~df[\"is_weekend\"]\n",
    "    return df\n",
    "\n",
    "agg2 = defaultdict(lambda: [0,0,0,0])  # [weekday_match, weekday_total, weekend_match, weekend_total]\n",
    "\n",
    "for chunk in pd.read_csv(TRIP_PATH, usecols=usecols_trip, dtype=dtype_trip, chunksize=chunksize):\n",
    "    chunk = chunk[chunk[\"trip_id\"].isin(ts_trip_ids)]\n",
    "    chunk = chunk[chunk[\"user_id\"].isin(target_user_ids)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"trip_date\"] = utc_string_to_local_date(chunk[\"request_time\"])\n",
    "    chunk[\"reserve_date\"] = utc_string_to_local_date(chunk[\"reserve_time\"])\n",
    "\n",
    "    chunk = chunk[\n",
    "        chunk[\"trip_date\"].between(start_minus_60, target_date_end) &\n",
    "        chunk[\"reserve_date\"].between(target_date_start, target_date_end)\n",
    "    ]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"week\"] = week_monday_from_date(chunk[\"trip_date\"])\n",
    "    chunk[\"is_match\"] = chunk[\"driver_id\"].notna()\n",
    "    chunk = add_weekend_flag_from_date(chunk, \"trip_date\")\n",
    "\n",
    "    chunk[\"weekday_match\"] = (chunk[\"is_match\"] & chunk[\"is_weekday\"]).astype(int)\n",
    "    chunk[\"weekend_match\"] = (chunk[\"is_match\"] & chunk[\"is_weekend\"]).astype(int)\n",
    "    chunk[\"weekday_total\"] = chunk[\"is_weekday\"].astype(int)\n",
    "    chunk[\"weekend_total\"] = chunk[\"is_weekend\"].astype(int)\n",
    "\n",
    "    g = chunk.groupby([\"user_id\",\"week\"], as_index=False)[\n",
    "        [\"weekday_match\",\"weekday_total\",\"weekend_match\",\"weekend_total\"]\n",
    "    ].sum()\n",
    "\n",
    "    for row in g.itertuples(index=False):\n",
    "        key = (int(row.user_id), row.week)\n",
    "        agg2[key][0] += int(row.weekday_match)\n",
    "        agg2[key][1] += int(row.weekday_total)\n",
    "        agg2[key][2] += int(row.weekend_match)\n",
    "        agg2[key][3] += int(row.weekend_total)\n",
    "\n",
    "trip_trip = pd.DataFrame(\n",
    "    [(k[0], k[1], v[0], v[1], v[2], v[3]) for k, v in agg2.items()],\n",
    "    columns=[\"user_id\",\"week\",\"weekday_match\",\"weekday_total\",\"weekend_match\",\"weekend_total\"]\n",
    ")\n",
    "trip_trip[\"weekday_match_rate\"] = (trip_trip[\"weekday_match\"] / trip_trip[\"weekday_total\"].replace({0:np.nan})).round(2)\n",
    "trip_trip[\"weekend_match_rate\"] = (trip_trip[\"weekend_match\"] / trip_trip[\"weekend_total\"].replace({0:np.nan})).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533bd2d9",
   "metadata": {},
   "source": [
    "## trip_label_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e398cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_PATH = \"../merged_data/trip_label_merged.csv\"\n",
    "\n",
    "usecols_tl = [\"trip_id\",\"user_id\",\"trip_date\",\"week\"]\n",
    "dtype_tl = {\"trip_id\":\"int64\",\"user_id\":\"int64\"}\n",
    "\n",
    "agg3 = defaultdict(lambda: [0,0,0])  # [weekday_trip_cnt, weekend_trip_cnt, trip_cnt]\n",
    "\n",
    "for chunk in pd.read_csv(TL_PATH, usecols=usecols_tl, dtype=dtype_tl, chunksize=chunksize):\n",
    "    chunk = chunk[~chunk[\"trip_id\"].isin(test_trip_ids)]\n",
    "    chunk = chunk[chunk[\"user_id\"].isin(target_user_ids)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"trip_date\"] = pd.to_datetime(chunk[\"trip_date\"], errors=\"coerce\").dt.date\n",
    "    chunk = chunk[chunk[\"trip_date\"].between(target_date_start, target_date_end)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"week\"] = pd.to_datetime(chunk[\"week\"], errors=\"coerce\").dt.date\n",
    "\n",
    "    chunk = add_weekend_flag_from_date(chunk, \"trip_date\")\n",
    "\n",
    "    g = chunk.groupby([\"user_id\",\"week\"], as_index=False).agg(\n",
    "        weekday_trip_cnt=(\"is_weekday\",\"sum\"),\n",
    "        weekend_trip_cnt=(\"is_weekend\",\"sum\"),\n",
    "        trip_cnt=(\"trip_id\",\"size\"),\n",
    "    )\n",
    "\n",
    "    for row in g.itertuples(index=False):\n",
    "        key = (int(row.user_id), row.week)\n",
    "        agg3[key][0] += int(row.weekday_trip_cnt)\n",
    "        agg3[key][1] += int(row.weekend_trip_cnt)\n",
    "        agg3[key][2] += int(row.trip_cnt)\n",
    "\n",
    "trip_label_agg = pd.DataFrame(\n",
    "    [(k[0], k[1], v[0], v[1], v[2]) for k, v in agg3.items()],\n",
    "    columns=[\"user_id\",\"week\",\"weekday_trip_cnt\",\"weekend_trip_cnt\",\"trip_cnt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cc2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_features: (1405448, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday_nonrepeat_cnt</th>\n",
       "      <th>weekend_nonrepeat_cnt</th>\n",
       "      <th>nonrepeat_cnt</th>\n",
       "      <th>weekday_match</th>\n",
       "      <th>weekday_total</th>\n",
       "      <th>weekend_match</th>\n",
       "      <th>weekend_total</th>\n",
       "      <th>weekday_match_rate</th>\n",
       "      <th>weekend_match_rate</th>\n",
       "      <th>weekday_trip_cnt</th>\n",
       "      <th>weekend_trip_cnt</th>\n",
       "      <th>trip_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        week  weekday_nonrepeat_cnt  weekend_nonrepeat_cnt  \\\n",
       "0       93  2025-12-01                    1.0                    0.0   \n",
       "1       93  2025-12-22                    1.0                    0.0   \n",
       "2       96  2025-08-11                    1.0                    0.0   \n",
       "3       96  2025-09-01                    3.0                    0.0   \n",
       "4       96  2025-09-08                    1.0                    0.0   \n",
       "\n",
       "   nonrepeat_cnt  weekday_match  weekday_total  weekend_match  weekend_total  \\\n",
       "0            1.0            1.0            1.0            0.0            0.0   \n",
       "1            1.0            0.0            0.0            0.0            1.0   \n",
       "2            1.0            0.0            0.0            1.0            1.0   \n",
       "3            3.0            1.0            1.0            2.0            2.0   \n",
       "4            1.0            0.0            0.0            1.0            1.0   \n",
       "\n",
       "   weekday_match_rate  weekend_match_rate  weekday_trip_cnt  weekend_trip_cnt  \\\n",
       "0                 1.0                 NaN               1.0               0.0   \n",
       "1                 NaN                 0.0               NaN               NaN   \n",
       "2                 NaN                 1.0               0.0               1.0   \n",
       "3                 1.0                 1.0               1.0               2.0   \n",
       "4                 NaN                 1.0               0.0               1.0   \n",
       "\n",
       "   trip_cnt  \n",
       "0       1.0  \n",
       "1       NaN  \n",
       "2       1.0  \n",
       "3       3.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_features = trip_stats_agg.merge(trip_trip, on=[\"user_id\",\"week\"], how=\"outer\")\n",
    "weekly_features = weekly_features.merge(trip_label_agg, on=[\"user_id\",\"week\"], how=\"outer\")\n",
    "\n",
    "print(\"weekly_features:\", weekly_features.shape)\n",
    "weekly_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bc1b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_metrics shape: (19326, 20)\n",
      "user_cleaned_with_metrics shape: (1569791, 21)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "GROUP_KEYS = [\"experiment_date\", \"treatment\", \"source\", \"ops_type_merged\", \"city\"]\n",
    "\n",
    "def week_monday_from_date(d: pd.Series) -> pd.Series:\n",
    "    dd = pd.to_datetime(d, errors=\"coerce\")\n",
    "    return (dd - pd.to_timedelta(dd.dt.weekday, unit=\"D\")).dt.date\n",
    "\n",
    "def safe_divide(a, b):\n",
    "    b = b.replace({0: np.nan})\n",
    "    return a / b\n",
    "\n",
    "# 1) user_cleaned: 補 week\n",
    "uc = user_cleaned.copy()\n",
    "uc[\"experiment_date\"] = pd.to_datetime(uc[\"experiment_date\"], errors=\"coerce\").dt.date\n",
    "uc[\"week\"] = week_monday_from_date(uc[\"experiment_date\"])\n",
    "uc[\"user_id\"] = pd.to_numeric(uc[\"user_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 2) 把 weekly_features 併回每一列 user_cleaned（每人/那週）\n",
    "wf = weekly_features.copy()\n",
    "wf[\"user_id\"] = pd.to_numeric(wf[\"user_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "wf[\"week\"] = pd.to_datetime(wf[\"week\"], errors=\"coerce\").dt.date\n",
    "\n",
    "ucw = uc.merge(wf, on=[\"user_id\", \"week\"], how=\"left\")\n",
    "\n",
    "# 3) 計數缺值補 0（表示該 user 在該週沒發生）\n",
    "count_cols = [\n",
    "    \"nonrepeat_cnt\", \"trip_cnt\",\n",
    "    \"weekday_nonrepeat_cnt\", \"weekend_nonrepeat_cnt\",\n",
    "    \"weekday_trip_cnt\", \"weekend_trip_cnt\",\n",
    "    \"weekday_match\", \"weekday_total\", \"weekend_match\", \"weekend_total\",\n",
    "]\n",
    "for c in count_cols:\n",
    "    if c in ucw.columns:\n",
    "        ucw[c] = pd.to_numeric(ucw[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 4) 依你要的維度做「組別彙總」\n",
    "g = ucw.groupby(GROUP_KEYS, as_index=False).agg(\n",
    "    user_cnt=(\"user_id\", \"nunique\"),\n",
    "    # 叫車數/趟次數（總和）\n",
    "    nonrepeat_cnt=(\"nonrepeat_cnt\", \"sum\"),\n",
    "    trip_cnt=(\"trip_cnt\", \"sum\"),\n",
    "    # 平假日叫車數/趟次\n",
    "    weekday_nonrepeat_cnt=(\"weekday_nonrepeat_cnt\", \"sum\"),\n",
    "    weekend_nonrepeat_cnt=(\"weekend_nonrepeat_cnt\", \"sum\"),\n",
    "    weekday_trip_cnt=(\"weekday_trip_cnt\", \"sum\"),\n",
    "    weekend_trip_cnt=(\"weekend_trip_cnt\", \"sum\"),\n",
    "    # 媒合聚合用 totals（最正確）\n",
    "    weekday_match=(\"weekday_match\", \"sum\"),\n",
    "    weekday_total=(\"weekday_total\", \"sum\"),\n",
    "    weekend_match=(\"weekend_match\", \"sum\"),\n",
    "    weekend_total=(\"weekend_total\", \"sum\"),\n",
    ")\n",
    "\n",
    "# 5) 人均欄位\n",
    "g[\"nonrepeat_cnt_per_user\"] = safe_divide(g[\"nonrepeat_cnt\"], g[\"user_cnt\"])\n",
    "g[\"trip_cnt_per_user\"] = safe_divide(g[\"trip_cnt\"], g[\"user_cnt\"])\n",
    "g[\"weekday_nonrepeat_cnt_per_user\"] = safe_divide(g[\"weekday_nonrepeat_cnt\"], g[\"user_cnt\"])\n",
    "g[\"weekend_nonrepeat_cnt_per_user\"] = safe_divide(g[\"weekend_nonrepeat_cnt\"], g[\"user_cnt\"])\n",
    "g[\"weekday_trip_cnt_per_user\"] = safe_divide(g[\"weekday_trip_cnt\"], g[\"user_cnt\"])\n",
    "g[\"weekend_trip_cnt_per_user\"] = safe_divide(g[\"weekend_trip_cnt\"], g[\"user_cnt\"])\n",
    "\n",
    "# 6) 媒合率（組別 = match總和 / total總和）\n",
    "g[\"weekday_match_rate\"] = safe_divide(g[\"weekday_match\"], g[\"weekday_total\"]).round(2)\n",
    "g[\"weekend_match_rate\"] = safe_divide(g[\"weekend_match\"], g[\"weekend_total\"]).round(2)\n",
    "\n",
    "# 如果你不想把中間的 match/total 留著，可以 drop\n",
    "g = g.drop(columns=[\"weekday_match\",\"weekday_total\",\"weekend_match\",\"weekend_total\"])\n",
    "\n",
    "# 7) merge 回 user_cleaned：同組每列都會帶同一套數字\n",
    "user_cleaned_with_metrics = uc.merge(g, on=GROUP_KEYS, how=\"left\").drop(columns=[\"week\"], errors=\"ignore\")\n",
    "\n",
    "print(\"group_metrics shape:\", g.shape)\n",
    "print(\"user_cleaned_with_metrics shape:\", user_cleaned_with_metrics.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46da6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>source</th>\n",
       "      <th>ops_type_merged</th>\n",
       "      <th>city</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>nonrepeat_cnt</th>\n",
       "      <th>trip_cnt</th>\n",
       "      <th>weekday_nonrepeat_cnt</th>\n",
       "      <th>weekend_nonrepeat_cnt</th>\n",
       "      <th>weekday_trip_cnt</th>\n",
       "      <th>weekend_trip_cnt</th>\n",
       "      <th>nonrepeat_cnt_per_user</th>\n",
       "      <th>trip_cnt_per_user</th>\n",
       "      <th>weekday_nonrepeat_cnt_per_user</th>\n",
       "      <th>weekend_nonrepeat_cnt_per_user</th>\n",
       "      <th>weekday_trip_cnt_per_user</th>\n",
       "      <th>weekend_trip_cnt_per_user</th>\n",
       "      <th>weekday_match_rate</th>\n",
       "      <th>weekend_match_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>5145040</td>\n",
       "      <td>15x2元1張</td>\n",
       "      <td>隨機組</td>\n",
       "      <td>14天在其他尖峰預估車資</td>\n",
       "      <td>臺北市</td>\n",
       "      <td>447</td>\n",
       "      <td>150.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.335570</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.196868</td>\n",
       "      <td>0.138702</td>\n",
       "      <td>0.134228</td>\n",
       "      <td>0.114094</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>302812</td>\n",
       "      <td>15x2元1張</td>\n",
       "      <td>隨機組</td>\n",
       "      <td>14天在其他尖峰預估車資</td>\n",
       "      <td>新北市</td>\n",
       "      <td>297</td>\n",
       "      <td>101.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.340067</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>0.276094</td>\n",
       "      <td>0.063973</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>4375821</td>\n",
       "      <td>15x2元1張</td>\n",
       "      <td>隨機組</td>\n",
       "      <td>14天在其他尖峰預估車資</td>\n",
       "      <td>新北市</td>\n",
       "      <td>260</td>\n",
       "      <td>54.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>2273154</td>\n",
       "      <td>15x2元1張</td>\n",
       "      <td>隨機組</td>\n",
       "      <td>14天在其他尖峰預估車資</td>\n",
       "      <td>臺北市</td>\n",
       "      <td>304</td>\n",
       "      <td>75.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>433188</td>\n",
       "      <td>15x2元1張</td>\n",
       "      <td>隨機組</td>\n",
       "      <td>14天在其他尖峰預估車資</td>\n",
       "      <td>臺北市</td>\n",
       "      <td>447</td>\n",
       "      <td>150.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.335570</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.196868</td>\n",
       "      <td>0.138702</td>\n",
       "      <td>0.134228</td>\n",
       "      <td>0.114094</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_date  user_id treatment source ops_type_merged city  user_cnt  \\\n",
       "0      2025-12-22  5145040   15x2元1張    隨機組    14天在其他尖峰預估車資  臺北市       447   \n",
       "1      2025-11-17   302812   15x2元1張    隨機組    14天在其他尖峰預估車資  新北市       297   \n",
       "2      2025-12-01  4375821   15x2元1張    隨機組    14天在其他尖峰預估車資  新北市       260   \n",
       "3      2025-11-24  2273154   15x2元1張    隨機組    14天在其他尖峰預估車資  臺北市       304   \n",
       "4      2025-12-22   433188   15x2元1張    隨機組    14天在其他尖峰預估車資  臺北市       447   \n",
       "\n",
       "   nonrepeat_cnt  trip_cnt  weekday_nonrepeat_cnt  weekend_nonrepeat_cnt  \\\n",
       "0          150.0     111.0                   88.0                   62.0   \n",
       "1          101.0      61.0                   82.0                   19.0   \n",
       "2           54.0      41.0                   39.0                   15.0   \n",
       "3           75.0      54.0                   52.0                   23.0   \n",
       "4          150.0     111.0                   88.0                   62.0   \n",
       "\n",
       "   weekday_trip_cnt  weekend_trip_cnt  nonrepeat_cnt_per_user  \\\n",
       "0              60.0              51.0                0.335570   \n",
       "1              47.0              14.0                0.340067   \n",
       "2              27.0              14.0                0.207692   \n",
       "3              34.0              20.0                0.246711   \n",
       "4              60.0              51.0                0.335570   \n",
       "\n",
       "   trip_cnt_per_user  weekday_nonrepeat_cnt_per_user  \\\n",
       "0           0.248322                        0.196868   \n",
       "1           0.205387                        0.276094   \n",
       "2           0.157692                        0.150000   \n",
       "3           0.177632                        0.171053   \n",
       "4           0.248322                        0.196868   \n",
       "\n",
       "   weekend_nonrepeat_cnt_per_user  weekday_trip_cnt_per_user  \\\n",
       "0                        0.138702                   0.134228   \n",
       "1                        0.063973                   0.158249   \n",
       "2                        0.057692                   0.103846   \n",
       "3                        0.075658                   0.111842   \n",
       "4                        0.138702                   0.134228   \n",
       "\n",
       "   weekend_trip_cnt_per_user  weekday_match_rate  weekend_match_rate  \n",
       "0                   0.114094                0.82                0.77  \n",
       "1                   0.047138                0.67                0.84  \n",
       "2                   0.053846                0.76                0.88  \n",
       "3                   0.065789                0.84                0.74  \n",
       "4                   0.114094                0.82                0.77  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "user_cleaned_with_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0deef31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\minhsiang.chang\\Desktop\\2026winter_project\\cleaned_data\\user_with_cnt_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"..\") / \"cleaned_data\" / \"user_with_cnt_cleaned.csv\"\n",
    "user_cleaned_with_metrics.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved:\", out_path.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
